---
title: "RePsychLing Iana Nikonova's 'Letter Identity Span' Experiment"
author: "Reinhold Kliegl"
date: today
date-format: iso
format: 
  html:
    embed-resources: true
    toc: true
    toc-depth: 3
    code-fold: false
    number-sections: true
    fig-width: 8
    fig-height: 6
    fig-format: svg
editor_options: 
  chunk_output_type: console
engine: julia
julia: 
  exeflags: ["--project", "--threads=auto"]
---

```{julia}
using Arrow
using CairoMakie
using DataFrames
using MixedModels
using MixedModelsExtras
using MixedModelsMakie
using RegressionFormulae
using RCall
using StatsModels
```


## Experiment description

This study investigates letter identity span in Russian-speaking adults. 92 native Russian speakers participated in this study. The gaze-contingent moving window paradigm (McConkie & Rayner, 1975) was used. In the experimental conditions, participants were able to perceive only a restricted number of characters to the left and right of the fixation point during sentence reading. Characters outside this visible window were substituted with visually analogous letters. This window of visible characters dynamically shifted in accordance with the participants’ gaze direction.The main aim of the experiment was to estimate the letter identity span in Russian by comparing different window conditions and to determine how reading speed differs from the control condition without masking.

In the code presented here, we analyze reading rate (measured in words per minute) as well as the number of regressions (regression count). The following questions arise in connection with the analysis:
How should a three-way interaction in a model be correctly interpreted?
How can differences between factor levels be tested when there are more than two levels?
What is the proper way to compare all factor levels with each other (e.g., 6 pairwise comparisons for 4 levels and more)?
Is the Poisson distribution appropriate for modeling the number of regressions, or would another distribution be more suitable?


## Dataset Variables

The dataset contains the following variables:

- `id`: Participant ID.  
- `list`: Experimental list.  
- `window`: Size of the right side of the visible window (the left side was constant at 3 characters). A value of 0 indicates no masking.  
- `wpm`: Reading rate measured in words per minute.  
- `reg_count`: Number of regressive saccades during the trial.  
- `index`: Sequential order of the trial within the recording session.  
- `accuracy`: Participant’s response accuracy to comprehension questions (`1` = correct, `0` = incorrect, `-1` = no question in trial).  
- `sentence_id`: Identifier of the presented sentence.  
- `sentence`: Text of the presented sentence.


# Data

```{julia}
# LMM data
data_LI_wpm = DataFrame(Arrow.Table("data_LI_wpm.arrow"));
describe(data_LI_wpm);

# GLMM data
data_LI_reg_c = DataFrame(Arrow.Table("data_LI_reg_c.arrow"));
describe(data_LI_reg_c);
```

```{julia}
contrasts = Dict(
  :window => HypothesisCoding(
       [
           -1      -1    -1   +3 
           -1      -1    +2    0
           -1      +1     0    0
          ];
          levels=["12", "14", "16", "0"],
          labels=["c0", "c16", "c14"]));
```

# LMMs

## Fitting the model

```{julia}
wpm_1 = let f = @formula (sqrt(wpm) ~ 1 + window + 
                                     (1 + window | id) + (1 + window | sentence_id))
       fit(MixedModel, f, data_LI_wpm; contrasts)
       end

issingular(wpm_1)      # true
MixedModels.PCA(wpm_1) # overparameterized for sentence_id
VarCorr(wpm_1)
coeftable(wpm_1)
```

This model converges, but is overparameterized for `sentence_id`.

## Fitting a model with uncorrelated random slope and intercept (sentence_id)

```{julia}
wpm_1_1 = let 
    f = @formula (sqrt(wpm) ~ 1 + window + (1 + window | id) + zerocorr(1 + window | sentence_id))
    fit(MixedModel, f, data_LI_wpm; contrasts)
   end
issingular(wpm_1_1)  # true
MixedModels.PCA(wpm_1_1)
VarCorr(wpm_1_1)
```

This model is overparameterized for `sentence_id`; zero-VC for c14.

```{julia}
wpm_2 = let 
   f = @formula (sqrt(wpm) ~ 1 + window + (1 + window | id) + (1 | sentence_id))
  fit(MixedModel, f, data_LI_wpm; contrasts)
  end
issingular(wpm_2) # false
MixedModels.PCA(wpm_2)
VarCorr(wpm_2)
coeftable(wpm_2)
```

This model looks ok.

## Fitting a model with uncorrelated random slope and intercept (id)

```{julia}
wpm_2_1 = let 
   f = @formula (sqrt(wpm) ~ 1 + window + zerocorr(1 + window | id) + (1 | sentence_id))
  fit(MixedModel, f, data_LI_wpm; contrasts)
  end
issingular(wpm_2_1) # false
MixedModels.PCA(wpm_2_1)
VarCorr(wpm_2_1)
```

This model looks ok.

## Only varying intercepts

```{julia}
wpm_3 = let 
   f = @formula (sqrt(wpm) ~ 1 + window + (1 | id) + (1 | sentence_id))
  fit(MixedModel, f, data_LI_wpm; contrasts)
  end
```

## Goodness of fit

```{julia}
lrtest(wpm_3, wpm_2_1, wpm_2, wpm_1_1, wpm_1)
```
```{julia}
table =[];
push!(table, wpm_3);  
push!(table, wpm_2_1);
push!(table, wpm_2);
push!(table, wpm_1_1); 
push!(table, wpm_1);

model_data = 
        gof_summary = let
        mods = eval.(table)
        DataFrame(;
          dof=dof.(mods),
          deviance=round.(deviance.(mods), digits=0),
          AIC=round.(aic.(mods),digits=0),
          BIC=round.(bic.(mods),digits=0)
        )
      end
```

All criteria -- LRT, AIC and BIC -- prefer wpm_2_1. 


# GLMMs

We can do this at SMLP2025.

## Contrasts

# Version

```{julia}
versioninfo()
```