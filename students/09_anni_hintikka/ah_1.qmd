---
title: "RePsychLing Anni Hintikka's Simulation of Cognate Processing"
author: "Reinhold Kliegl"
date: today
date-format: iso
format: 
  html:
    embed-resources: true
    toc: true
    toc-depth: 3
    code-fold: false
    number-sections: true
    fig-width: 8
    fig-height: 6
    fig-format: svg
editor_options: 
  chunk_output_type: console
engine: julia
julia: 
  exeflags: ["--project", "--threads=auto"]
---

```{julia}
using Arrow
using CairoMakie
using DataFrames
using MixedModels
using MixedModelsExtras
using MixedModelsMakie
using RegressionFormulae
using RCall
using StatsModels
```

# Background & variables

## Theoretical background

Cognates are words that have a similar orthographic and phonological form and (roughly) the same meaning between two or more languages. 

For example the word *science* is a cognate between English and French. Cognates have varying degrees of orthographic and phonological similarity. For example, the word *science* (FR:*science*) is orthographically identical in English and in French, whereas *onion* (FR: *oignon*) is not. Similarly, the word *enemy* (FR: *ennemi*) is pronounced identically in both languages [ɛnəmi], [ɛnəmɪ], while the word *rumor* (FR: *rumeur*) sounds  more dissimilar between the languages: [ɹuːmə*], [ʁymœʁ].

Cognate words are usually recognized faster and more accurately than non-cognate words. However, it is not yet clear how the degree of similarity affects cognate word recognition. My goal is to see how the degree of orthographic and phonological similarity affect cognate and non-cognate word recognition in both visual and auditory modalities among L1 Finnish learners of L3 French. The learners perform auditory and visual lexical decision tasks and their reaction time (as well as accuracy rates; not included in this example) is measured.

The data is simulated for 60 participants.

## Covariates

+ participant. There are 60 simulated participants.
+ modality. The modality of presentation: visual (V) or auditory (A). This is why each word is repeated twice in the data.
+ ortho_French. Word/item to be recognized
+ inversed_aline. The measure of phonological similarity, ranging from 0 to 1. 0 means total dissimilarity between phonological forms, 1 means the phonological forms are identical.
+ lev_similarity. The measure of orhtographic similarity, ranging from 0 to 1. 0 means total dissimilarity between phonological forms, 1 means the phonological forms are identical. 
+ type. Whether a word is cognate or a non-cognate. For now, this is not considered in the analysis. **There are now 96 non-cognate items and 48 cognate items**, if this information somehow affects the interpretation/modedling. All cognates have an orthographic similarity above 0.5.
+ first_modality. The participants are divided into two groups for the experiment. 30 participants have visual modality first (V) and 30 have auditory modality first (A). Not included in the model for now.
+ list. This refers to the experimental list given to the participants. There are 3 different lists. For now, this is not considered in the analysis.

*Please note that inversed_aline and lev_similarity are calculated differently; inversed_aline takes phonological features into account).

*Please note that inversed_aline and lev_similarity are probably highly intercorrelated. This hasn't been adressed in this example, but it will probably cause multicollinearity problems. There are solutions to this, for example using residuals.

## Dependent variable 

+ RT. Reaction time: how long did it take for the participant to give a yes response after seeing or hearing a word. These are simulated. I simulated the RTs according to these expected results:
+ Auditory modality (A): Word recognition is 120 ms faster when words are phonologically more similar, 80 ms slower when words are orthographically more similar.
+ Visual modality (V): Word recognition is 120 ms faster when words are orthographically more similar, 80 ms slower when words are phonologically more similar.

# Data

```{julia}
df_rk = DataFrame(Arrow.Table("df_rk.arrow"));
describe(df_rk)
```

# Contrasts

```{julia}
contrasts = Dict(
  :Mod  => EffectsCoding(),
  :Type => EffectsCoding(),
  :FM   => EffectsCoding()
)
```

# LMMs

## Test of "main"" effects

The three main effects are reduced versions of the original five factors.

### DV: Response

```{julia}
m3 = let f = @formula rt ~ 1 + ls * ia * Mod +
                          (1 + ls + ia + Mod | Subj) + 
                          (1 + ls + ia + Mod | Item)
       fit(MixedModel, f, df_rk; contrasts)
       end

issingular(m3)      # true
MixedModels.PCA(m3) # overparameterized for sentence_id
VarCorr(m3)
coeftable(m3)
```

Contrast with LMM assuming only varing intercepts (ovi).

```{julia}
m3_ovi = let f = @formula rt ~ 1 + ls * ia * Mod + (1 | Subj) + (1 | Item)
       fit(MixedModel, f, df_rk; contrasts)
       end

show(coeftable(m3_ovi))


lrtest(m3_ovi, m3)
```

Random effects were not part of the simulation.
Let's check the interactions.

```{julia}
m2 = let f = @formula rt ~ 1 + (ls + ia + Mod)^2 + (1 | Subj) + (1 | Item)
       fit(MixedModel, f, df_rk; contrasts)
       end

show(coeftable(m2))

lrtest(m2, m3_ovi, m3)
```

There is no evidence for a three-covariate interaction. How about two-covariate interactions?

```{julia}
m1 = let f = @formula rt ~ 1 + ls + ia + Mod + (1 | Subj) + (1 | Item)
       fit(MixedModel, f, df_rk; contrasts)
       end

show(coeftable(m1))

lrtest(m1, m2, m3_ovi, m3)
```

They are significant. Specifically, ls and ia interact with modality.

# GoF stats

## for `Response`

```{julia}
table =[];
push!(table, m1);  
push!(table, m2);
push!(table, m3_ovi);
push!(table, m3); 

model_data = 
        gof_summary = let
        mods = eval.(table)
        DataFrame(;
          dof=dof.(mods),
          deviance=round.(deviance.(mods), digits=0),
          AIC=round.(aic.(mods),digits=0),
          BIC=round.(bic.(mods),digits=0)
        )
      end
```


All criteria prefer LMM `m2`.

## Residual diagnostics

## Q-Q plot: LMM m2

```{julia}
CairoMakie.activate!(; type="png")

MixedModelsMakie.qqnorm(
  residuals(m2);
  qqline=:none,
  axis=(;
    xlabel="Standard normal quantiles",
    ylabel="Quantiles of the residuals from model m2",
  )
)
```

Suggest deviation. Possibly rt's were simulated from 

```{julia}
m2_log = let f = @formula log(rt) ~ 1 + (ls + ia + Mod)^2 + (1 | Subj) + (1 | Item)
       fit(MixedModel, f, df_rk; contrasts)
       end

show(coeftable(m2_log))
```

## Q-Q plot: LMM m2_log

```{julia}
CairoMakie.activate!(; type="png")

MixedModelsMakie.qqnorm(
  residuals(m2_log);
  qqline=:none,
  axis=(;
    xlabel="Standard normal quantiles",
    ylabel="Quantiles of the residuals from model m2_log",
  )
)
```

Looks definitely better.


# Version

```{julia}
versioninfo()
```